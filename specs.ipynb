{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CNH6ZbJN0AOdxwu6QkltS_EukH7Q3vnv",
      "authorship_tag": "ABX9TyP0GmxkX4m3CKlCStFKVABz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Isikabag23/Specs_detection_model/blob/main/specs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Mx003FNhx-5",
        "outputId": "e7e2669c-eb75-4ca7-9811-a607033689ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400 images belonging to 5 classes.\n",
            "Found 99 images belonging to 5 classes.\n",
            "Epoch 1/10\n",
            "13/13 [==============================] - 1453s 113s/step - loss: 9.6470 - accuracy: 0.2300 - val_loss: 1.9620 - val_accuracy: 0.3131\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 1496s 116s/step - loss: 1.9777 - accuracy: 0.3825 - val_loss: 1.2817 - val_accuracy: 0.4949\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 1492s 117s/step - loss: 1.1878 - accuracy: 0.5100 - val_loss: 1.1645 - val_accuracy: 0.4747\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 1485s 116s/step - loss: 1.0169 - accuracy: 0.6050 - val_loss: 1.1383 - val_accuracy: 0.5556\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 1453s 113s/step - loss: 1.0058 - accuracy: 0.5475 - val_loss: 0.9892 - val_accuracy: 0.6162\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 1487s 116s/step - loss: 0.8938 - accuracy: 0.6350 - val_loss: 0.9544 - val_accuracy: 0.6465\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 1495s 116s/step - loss: 0.8988 - accuracy: 0.6275 - val_loss: 0.8426 - val_accuracy: 0.6970\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 1493s 117s/step - loss: 0.7809 - accuracy: 0.6625 - val_loss: 1.1440 - val_accuracy: 0.5354\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 1494s 116s/step - loss: 0.8980 - accuracy: 0.6450 - val_loss: 0.8899 - val_accuracy: 0.6465\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 1486s 116s/step - loss: 0.7246 - accuracy: 0.6975 - val_loss: 0.8217 - val_accuracy: 0.7071\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the image dimensions and other parameters\n",
        "img_width, img_height = 474,474\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "num_classes = 5  # Number of weather categories\n",
        "\n",
        "# Load the pre-trained VGG16 model without the top layer\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "# Freeze the pre-trained layers so they are not trained during the Weather detection process\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a new model\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory('/content/drive/MyDrive/abcd/Train', target_size=(img_width, img_height),\n",
        "                                                    batch_size=batch_size, class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory('/content/drive/MyDrive/abcd/Test', target_size=(img_width, img_height),\n",
        "                                                        batch_size=batch_size, class_mode='categorical')\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator,  epochs=epochs,validation_data=validation_generator)\n",
        "# Save the trained model\n",
        "model.save('specs_det_model.h5')"
      ]
    }
  ]
}